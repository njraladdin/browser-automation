


test without the sekeleton view 
test with image 

being able to see and extract data on a page not just interative elements 




test by extrracintg listings from airbnb / extract list of followers on instagram 



save autoamtion flow 
being able to rerun a step 


-----

fix selecting elements not working on airbnb (simplfy, keep array on backend, use polling in frontend)

----



try another appraoch: 


currenty: extraction isn't working well by writing code to extract data 

selection is not necessary anymore, remove it 

only get interactive elements that are currently visible on the page 

so for automation : provide interactive map of visible elements on the page / source of current sivile elements on the page 
for data extraction : the AI writes a prompt on the data to extract, then it uses a function that calls another gemini request with full source of page (cleaned) 


the interactive map: for the ai to know what he's bale to interact with 
the page source: for the ai to know what exists on the page (content)

problem: 
airbnb website has very long selectors + huge source


todo: 
remove selection done
compress selectors, and decompress it in result code done
make the page source only contain  the contents and links (or as a new view, to be safe) done
create a functino taht woudl recevie the page content and the prompt, and output the json (use gemini flash 8b) done 
make the AI be able to detect that ishoudl use the function and use it in case of need for data extraction done 



display extracted data in frontend, done 
AI shoudl have acess to extracted data (number, first item and last item), done 
keep screenshot preview of the page in frontend and send it after each step, done 
you can create and save flows, done 
you can play a single step, done 
make step UI conssitent before and after adding (same layout), done 
run websocket server to easily track what's happening in the backend (to easily debug what's going on evne when backend is deployed), done 
add timeout to close the browser after 20 minutes of intilizing a flow, done 
create profile, so flows are connected to each user profile (for simplciity, user creates / signs it with just his username), done 
add your own gemini key to the project, done 
be bale to delete a step , done 
allow ai to colelct data and push it to frontend, nto just the extract function, done 



run each benchmark, troubleshoot and improve :
- go to anonymiosu instagram stories, open each story modal and get all stories posts :
    Problem: buttons do not have text, and AI is choosing wrong button selector to submit search, DONE 
    Solutions: - send image of page and label each element. - add nearby text to each element

    Problem: an error might face the scritp while running due to some change in page structure
    Problem: it clicks on wrong elements 
    Solutions: 
    -when catching an error, resend the script to gemini with error message and new snapshot, and update script . 

    - the step should be split into  actions, and gemini would be able to see the result of each action, like a real person

    - give labeled screenshots to gemini after every action 

    - don't generate the full script at once. isntead it generates first action, it runs it, then gemini sees the result, then gemini generates the next action, and so on. 
    result include snbapshot and also screenshot

    - implement an AI inspector betwene each item, where after every action, it reviews the website and check if it's well, then it let it move forward, otherwise it udpates the code then continues form where it left off. 
  
    - simpler: generate first action, review output and website, then generate next action, and so on. 

    - make the automation code itself also use AI, so not simply autoamtion oc,dde but lawasy relies on ai . MOR RELIANT ON AI 

    -send sreenshot of page 

    -send screenshots of parts of the page you're talking about 

    - send pagehtml 

    - !important: recursive code genreation: the ai can also use a function generateCodeHere(code) in the mdidle of the puppeteer code, which genreates the code there with  up to date snapshot

benchmarks: 
- go to airbnb,scroll to load all listings, extract all listings details 
- go to anonymiosu instagram stories, and get latest stories 
- go to twitter profile, and extract list of tweets until you get 100
- go to airbnb, search a destination, then extract all data for each pagination page


oh the AI only gets the page snapshot (html , interactive elements) once at the beginning, so thne he goes to open the modal and he deosnt know the exact html of the modal. but he does have acess to previous code. doesn't he have access to this line from previsou code: 
    const imgElement = document.querySelector('.media-modal__content img');


which he could use to detect ht modal? i meant from the preivous code he literally did this corectly ? 